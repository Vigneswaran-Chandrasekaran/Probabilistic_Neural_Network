{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extracting features and use PNN to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Dataset processing completed\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "from wavelet_transform import bonn_dataset\n",
    "raw_data = np.load(\"../Healthcare_signal_processing/Datasets/Bonn/data_all.npz\")\n",
    "decomposed_data = bonn_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Extract necessary features from time-domain raw signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 4097)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data_healthy = np.vstack((raw_data['z'], raw_data['o']))   # healthy subjects\n",
    "raw_data_inter_ictal = np.vstack((raw_data['n'], raw_data['f']))   # inter-ictal subjects\n",
    "raw_data_ictal = np.vstack(raw_data['s'])                          # ictal subjects\n",
    "raw_data_non_ictal = np.vstack((raw_data_healthy, raw_data_inter_ictal))  # non-ictal subjects\n",
    "raw_data_all = np.vstack((raw_data_non_ictal, raw_data_ictal))   # all\n",
    "raw_data_all.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature set 1: Statistical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minn = np.amin(raw_data_all, axis = 1)\n",
    "maxx = np.amax(raw_data_all, axis = 1)\n",
    "rangee = maxx - minn\n",
    "mean = np.mean(raw_data_all, axis = 1)\n",
    "median = np.median(raw_data_all, axis = 1)\n",
    "mode = np.array(stats.mode(raw_data_all, axis = 1)[0]).reshape(-1)\n",
    "kurt = stats.kurtosis(raw_data_all, axis = 1)\n",
    "skew = stats.skew(raw_data_all, axis = 1)\n",
    "first_qua = np.quantile(raw_data_all, 0.25, axis = 1)\n",
    "third_qua = np.quantile(raw_data_all, 0.75, axis = 1)\n",
    "inter_qua = third_qua - first_qua\n",
    "std = np.std(raw_data_all, axis = 1)\n",
    "time_domain_stat_features = np.vstack((minn, maxx, rangee, mean, median, mode, kurt, skew, first_qua, \n",
    "                                 third_qua, inter_qua, std)).T\n",
    "print(\"[INFO] Time domain statistical features extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature set 2: Hjorth based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time domain Hjorth features extracted\n"
     ]
    }
   ],
   "source": [
    "import pyeeg\n",
    "hjorth_mob = []\n",
    "hjorth_com = []\n",
    "for samp in raw_data_all:\n",
    "    hjorth = pyeeg.hjorth_mobility_complexity.hjorth(samp)\n",
    "    hjorth_mob.append(hjorth[0])\n",
    "    hjorth_com.append(hjorth[1])\n",
    "hjorth_mob = np.array(hjorth_mob)\n",
    "hjorth_com = np.array(hjorth_com)\n",
    "hjorth_act = np.var(raw_data_all, axis = 1)\n",
    "time_domain_hjorth_features = np.vstack((hjorth_mob, hjorth_com, hjorth_act)).T\n",
    "print(\"[INFO] Time domain Hjorth features extracted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature set 3: Special time domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Time domain Hjorth features extracted\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa = []\n",
    "pfd = []\n",
    "for samp in raw_data_all:\n",
    "    #hurst.append(pyeeg.hurst(samp))\n",
    "    dfa.append(pyeeg.detrended_fluctuation_analysis.dfa(samp))\n",
    "    pfd.append(pyeeg.fractal_dimension.pfd(samp))\n",
    "time_domain_special_features = np.vstack((np.array(dfa), np.array(pfd))).T\n",
    "print(\"[INFO] Time domain Hjorth features extracted\")\n",
    "time_domain_special_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Feature set 4: Wavelet based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vicky/anaconda3/lib/python3.7/site-packages/pyentrp/entropy.py:178: RuntimeWarning: divide by zero encountered in log\n",
      "  sampen =  - np.log(Ntemp[1:] / Ntemp[:-1])\n",
      "/home/vicky/anaconda3/lib/python3.7/site-packages/pyentrp/entropy.py:178: RuntimeWarning: invalid value encountered in true_divide\n",
      "  sampen =  - np.log(Ntemp[1:] / Ntemp[:-1])\n"
     ]
    }
   ],
   "source": [
    "from pyentrp import entropy\n",
    "sample = []\n",
    "shan = []\n",
    "perm = []\n",
    "muscale = []\n",
    "for samp in raw_data_all:\n",
    "    sample.append(entropy.sample_entropy(samp, 4, 0.2 * np.std(samp)))\n",
    "    shan.append(entropy.shannon_entropy(samp))\n",
    "    perm.append(entropy.permutation_entropy(samp))\n",
    "    muscale.append(entropy.multiscale_entropy(samp, 2))\n",
    "wavelet_features = np.vstack((np.array(dfa), np.array(pfd))).T\n",
    "print(\"[INFO] Wavelet domain entropy features extracted\")\n",
    "wavelet_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.hstack((time_domain_stat_features, time_domain_hjorth_features, time_domain_special_features,\n",
    "                     wavelet_features))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
